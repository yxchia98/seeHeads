{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/NanoCode012/OIDv6_ToolKit_Download_Open_Images_Support_Yolo_Format.git\n!git clone https://github.com/ultralytics/yolov5","metadata":{"id":"YuSbHPx5h7tJ","execution":{"iopub.status.busy":"2021-10-31T05:51:29.685821Z","iopub.execute_input":"2021-10-31T05:51:29.686280Z","iopub.status.idle":"2021-10-31T05:51:36.597557Z","shell.execute_reply.started":"2021-10-31T05:51:29.686153Z","shell.execute_reply":"2021-10-31T05:51:36.596759Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install -r /kaggle/working/OIDv6_ToolKit_Download_Open_Images_Support_Yolo_Format/requirements.txt\n!pip install -r /kaggle/working/yolov5/requirements.txt","metadata":{"id":"Ohswe5tGlqTT","execution":{"iopub.status.busy":"2021-10-29T04:50:44.00506Z","iopub.execute_input":"2021-10-29T04:50:44.005367Z","iopub.status.idle":"2021-10-29T04:50:59.01496Z","shell.execute_reply.started":"2021-10-29T04:50:44.005318Z","shell.execute_reply":"2021-10-29T04:50:59.014062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%mkdir /kaggle/working/OIDv6_ToolKit_Download_Open_Images_Support_Yolo_Format/OID/Dataset/","metadata":{"id":"udU7CTJFjOvO","execution":{"iopub.status.busy":"2021-10-29T04:51:16.20071Z","iopub.execute_input":"2021-10-29T04:51:16.200994Z","iopub.status.idle":"2021-10-29T04:51:16.857299Z","shell.execute_reply.started":"2021-10-29T04:51:16.200966Z","shell.execute_reply":"2021-10-29T04:51:16.85639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd /kaggle/working/OIDv6_ToolKit_Download_Open_Images_Support_Yolo_Format/\n!python3 main.py downloader -y --classes Human_head --type_csv train --limit 700 --yoloLabelStyle --Dataset /kaggle/working/","metadata":{"id":"0FzsCHNIij_p","execution":{"iopub.status.busy":"2021-10-29T04:51:38.71249Z","iopub.execute_input":"2021-10-29T04:51:38.712756Z","iopub.status.idle":"2021-10-29T04:59:55.859523Z","shell.execute_reply.started":"2021-10-29T04:51:38.712728Z","shell.execute_reply":"2021-10-29T04:59:55.858533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python3 main.py downloader -y --classes Human_head --type_csv validation --limit 200 --yoloLabelStyle --Dataset /kaggle/working/","metadata":{"id":"lPHzyXyvj8wW","execution":{"iopub.status.busy":"2021-10-29T05:01:25.616766Z","iopub.execute_input":"2021-10-29T05:01:25.617042Z","iopub.status.idle":"2021-10-29T05:03:44.556326Z","shell.execute_reply.started":"2021-10-29T05:01:25.617012Z","shell.execute_reply":"2021-10-29T05:03:44.55552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python3 main.py downloader -y --classes Human_head --type_csv test --limit 100 --yoloLabelStyle --Dataset /kaggle/working/","metadata":{"id":"0pefrsXx_HUR","execution":{"iopub.status.busy":"2021-10-29T05:03:46.436508Z","iopub.execute_input":"2021-10-29T05:03:46.437201Z","iopub.status.idle":"2021-10-29T05:05:02.001584Z","shell.execute_reply.started":"2021-10-29T05:03:46.437163Z","shell.execute_reply":"2021-10-29T05:05:02.000724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Data using Yolov5 pretrained models","metadata":{"id":"-CHAyx-ssrRU"}},{"cell_type":"markdown","source":"# Data Config File\nDetails for the dataset you want to train your model on are defined by the data config YAML file. The following parameters have to be defined in a data config file:\n\n* train, test, and val: Locations of train, test, and validation images.\n* nc: Number of classes in the dataset.\n* names: Names of the classes in the dataset. The index of the classes in this * list would be used as an identifier for the class names in the code.\n* Create a new file called people_det_data.yaml and place it in the yolov5/data folder. Then populate it with the following.\n\n\n\n```\ntrain: /kaggle/working/train/Human body/images/ \nval:  /kaggle/working/validation/Human body/images/\ntest: /kaggle/working/test/Human body/images/\n\n# number of classes\nnc: 1\n\n# class names\nnames: [\"person\"]\n```","metadata":{"id":"YUQ07C7mtrBa"}},{"cell_type":"markdown","source":"# Train the model YOLOv5\nIn the downloaded package of YOLOv5, we have 4 versions of the model: YOLOv5s, YOLOv5m, YOLOv5l and, YOLOv5x. I will use the small one and it is YOLOv5s. You guessed it the letters s, m, l, and x is for the model size.\nIn the training command, you give the selected model these arguments:\n* **img**: input image size\n* **batch**: batch size\n* **epochs**: number of training epochs\n* **data**: our yaml file created before\n* **cfg**: the chosen model here I used the small one\n* **weights**: a custom path to weights if empty, it will be saved in yolov5/runs/\n* **train**/yolov5_results/weights\n* **name**: result names\n* **device**: 0 to use GPU\n* **cache**: cache images for faster training","metadata":{"id":"Uv3CLekNENjz"}},{"cell_type":"markdown","source":"Train using yolov5s","metadata":{"id":"wzsc-cCiD9JI"}},{"cell_type":"code","source":"%cd /kaggle/working/yolov5\n!python train.py --img 640 --cfg yolov5s.yaml --hyp hyp.scratch.yaml --batch 16 --epochs 30 --data people_det_data_kaggle.yaml --weights yolov5s.pt --name yolo_people_det --device 0","metadata":{"id":"uRQS1lw1qJKg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"or train using yolov5s6","metadata":{"id":"dwowCzxbEBYh"}},{"cell_type":"code","source":"%cd /kaggle/working/yolov5\n!python train.py --img 1280 --cfg yolov5s6.yaml --hyp hyp.scratch.yaml --batch 16 --epochs 100 --data people_det_data_kaggle.yaml --weights yolov5s6.pt --name yolo_people_det","metadata":{"id":"msqUTd52DT_p"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Save the trained model and weights","metadata":{"id":"CpgKjmDfSIOJ"}},{"cell_type":"code","source":"!zip -r /kaggle/working/yolo_people_det.zip /kaggle/working/yolov5/runs/train/yolo_people_det","metadata":{"id":"sep9TtB2v2TE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from google.colab import files\nfiles.download('/content/yolov5/runs/train/yolo_people_det.zip')","metadata":{"id":"kcxWzeQE7jaN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference\nThere are many ways to run inference using the detect.py file.\n\nThe source flag defines the source of our detector, which can be:\n* A single image\n* A folder of images\n* Video\n* Webcam \\\n...and various other formats. We want to run it over our test images so we set the source flag to /content/test/Human.\n\n* The weights flag defines the path of the model which we want to run our detector with.\n* conf flag is the thresholding objectness confidence.\n* name flag defines where the detections are stored. We set this flag to yolo_road_det; therefore, the detections would be stored in runs/detect/yolo_road_det/.\nWith all options decided, let us run inference over our test dataset.","metadata":{"id":"omgf0RdhSsJP"}},{"cell_type":"code","source":"%cd /content/yolov5\n!python detect.py --source /content/yolov5/data/videos/people_walking.mp4 --weights runs/train/yolo_people_det/weights/best.pt --conf 0.25 --name yolo_people_det","metadata":{"id":"q_vH1wLvSWMx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"SW33xzcz9a1x"},"execution_count":null,"outputs":[]}]}