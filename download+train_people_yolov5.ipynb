{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "download+train_people_yolov5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuSbHPx5h7tJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "486b4de2-d513-40cb-e2d0-2e06af2d8c9c"
      },
      "source": [
        "!git clone https://github.com/NanoCode012/OIDv6_ToolKit_Download_Open_Images_Support_Yolo_Format.git\n",
        "!git clone https://github.com/ultralytics/yolov5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'OIDv6_ToolKit_Download_Open_Images_Support_Yolo_Format'...\n",
            "remote: Enumerating objects: 548, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (6/6), done.\u001b[K\n",
            "remote: Total 548 (delta 2), reused 0 (delta 0), pack-reused 542\u001b[K\n",
            "Receiving objects: 100% (548/548), 34.16 MiB | 14.09 MiB/s, done.\n",
            "Resolving deltas: 100% (218/218), done.\n",
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 9848, done.\u001b[K\n",
            "remote: Total 9848 (delta 0), reused 0 (delta 0), pack-reused 9848\u001b[K\n",
            "Receiving objects: 100% (9848/9848), 10.18 MiB | 12.96 MiB/s, done.\n",
            "Resolving deltas: 100% (6825/6825), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ohswe5tGlqTT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "087dd5e6-93f2-4e2d-a461-7931957a2ae2"
      },
      "source": [
        "!pip install -r /content/OIDv6_ToolKit_Download_Open_Images_Support_Yolo_Format/requirements.txt\n",
        "!pip install -r /content/yolov5/requirements.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r /content/OIDv6_ToolKit_Download_Open_Images_Support_Yolo_Format/requirements.txt (line 1)) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r /content/OIDv6_ToolKit_Download_Open_Images_Support_Yolo_Format/requirements.txt (line 2)) (1.19.5)\n",
            "Collecting awscli\n",
            "  Downloading awscli-1.21.7-py3-none-any.whl (3.7 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.7 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from -r /content/OIDv6_ToolKit_Download_Open_Images_Support_Yolo_Format/requirements.txt (line 5)) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r /content/OIDv6_ToolKit_Download_Open_Images_Support_Yolo_Format/requirements.txt (line 7)) (4.62.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r /content/OIDv6_ToolKit_Download_Open_Images_Support_Yolo_Format/requirements.txt (line 9)) (4.1.2.30)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r /content/OIDv6_ToolKit_Download_Open_Images_Support_Yolo_Format/requirements.txt (line 1)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r /content/OIDv6_ToolKit_Download_Open_Images_Support_Yolo_Format/requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->-r /content/OIDv6_ToolKit_Download_Open_Images_Support_Yolo_Format/requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: PyYAML<5.5,>=3.10 in /usr/local/lib/python3.7/dist-packages (from awscli->-r /content/OIDv6_ToolKit_Download_Open_Images_Support_Yolo_Format/requirements.txt (line 3)) (3.13)\n",
            "Collecting colorama<0.4.4,>=0.2.5\n",
            "  Downloading colorama-0.4.3-py2.py3-none-any.whl (15 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 79 kB 7.9 MB/s \n",
            "\u001b[?25hCollecting docutils<0.16,>=0.10\n",
            "  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 547 kB 44.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: rsa<4.8,>=3.1.2 in /usr/local/lib/python3.7/dist-packages (from awscli->-r /content/OIDv6_ToolKit_Download_Open_Images_Support_Yolo_Format/requirements.txt (line 3)) (4.7.2)\n",
            "Collecting botocore==1.22.7\n",
            "  Downloading botocore-1.22.7-py3-none-any.whl (8.1 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8.1 MB 32.5 MB/s \n",
            "\u001b[?25hCollecting urllib3\n",
            "  Downloading urllib3-1.26.7-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 138 kB 52.3 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<4.8,>=3.1.2->awscli->-r /content/OIDv6_ToolKit_Download_Open_Images_Support_Yolo_Format/requirements.txt (line 3)) (0.4.8)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, docutils, colorama, awscli\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.17.1\n",
            "    Uninstalling docutils-0.17.1:\n",
            "      Successfully uninstalled docutils-0.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.7 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed awscli-1.21.7 botocore-1.22.7 colorama-0.4.3 docutils-0.15.2 jmespath-0.10.0 s3transfer-0.5.0 urllib3-1.26.7\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov5/requirements.txt (line 4)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov5/requirements.txt (line 5)) (1.19.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov5/requirements.txt (line 6)) (4.1.2.30)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov5/requirements.txt (line 7)) (7.1.2)\n",
            "Collecting PyYAML>=5.3.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 596 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov5/requirements.txt (line 9)) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov5/requirements.txt (line 10)) (1.4.1)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov5/requirements.txt (line 11)) (1.9.0+cu111)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov5/requirements.txt (line 12)) (0.10.0+cu111)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov5/requirements.txt (line 13)) (4.62.3)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov5/requirements.txt (line 16)) (2.6.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov5/requirements.txt (line 20)) (1.1.5)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r /content/yolov5/requirements.txt (line 21)) (0.11.2)\n",
            "Collecting thop\n",
            "  Downloading thop-0.0.31.post2005241907-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r /content/yolov5/requirements.txt (line 4)) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r /content/yolov5/requirements.txt (line 4)) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r /content/yolov5/requirements.txt (line 4)) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r /content/yolov5/requirements.txt (line 4)) (2.8.2)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 127 kB 52.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r /content/yolov5/requirements.txt (line 9)) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r /content/yolov5/requirements.txt (line 9)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r /content/yolov5/requirements.txt (line 9)) (2.10)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r /content/yolov5/requirements.txt (line 11)) (3.7.4.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (1.41.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (0.4.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (3.17.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (0.37.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (0.6.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (1.35.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (1.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (0.12.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (3.3.4)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->-r /content/yolov5/requirements.txt (line 20)) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard>=2.4.1->-r /content/yolov5/requirements.txt (line 16)) (3.6.0)\n",
            "Installing collected packages: urllib3, thop, PyYAML\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.7\n",
            "    Uninstalling urllib3-1.26.7:\n",
            "      Successfully uninstalled urllib3-1.26.7\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "awscli 1.21.7 requires PyYAML<5.5,>=3.10, but you have pyyaml 6.0 which is incompatible.\u001b[0m\n",
            "Successfully installed PyYAML-6.0 thop-0.0.31.post2005241907 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udU7CTJFjOvO"
      },
      "source": [
        "%mkdir /content/OIDv6_ToolKit_Download_Open_Images_Support_Yolo_Format/OID/Dataset/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FzsCHNIij_p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9d37cf9-f78f-40df-e341-58957ce9befe"
      },
      "source": [
        "%cd /content/OIDv6_ToolKit_Download_Open_Images_Support_Yolo_Format/\n",
        "!python3 main.py downloader -y --classes Human_head --type_csv train --limit 700 --yoloLabelStyle --Dataset /content/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/OIDv6_ToolKit_Download_Open_Images_Support_Yolo_Format\n",
            "    [INFO] |  saving dataset configurations at /content/config.json\u001b[0m\n",
            "\u001b[92m\n",
            "\t\t   ___   _____  ______            _    _       _    _  \n",
            "\t\t .'   `.|_   _||_   _ `.         | |  | |     | |  | |    \n",
            "\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_    |  | | |   \n",
            "\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _|     | | | \n",
            "\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_       | |\n",
            "\t\t `.___.'|_____||______.'   \\__/     |_____|     |_|\n",
            "\t\u001b[0m\n",
            "\u001b[92m\n",
            "             _____                    _                 _             \n",
            "            (____ \\                  | |               | |            \n",
            "             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n",
            "            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n",
            "            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n",
            "            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n",
            "                                                          \n",
            "        \u001b[0m\n",
            "    [INFO] | Downloading Human head.\u001b[0m\n",
            "\u001b[91m   [ERROR] | Missing the train-annotations-bbox.csv file.\u001b[0m\n",
            "\u001b[94m[DOWNLOAD] | Automatic download.\u001b[0m\n",
            "...100%, 1138 MB, 24586 KB/s, 47 seconds passed\n",
            "\u001b[94m[DOWNLOAD] | File train-annotations-bbox.csv downloaded into ./OID/csv_folder/train-annotations-bbox.csv.\u001b[0m\n",
            "\n",
            "\u001b[95mHuman head\u001b[0m\n",
            "    [INFO] | Downloading train images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 49308 online images for train.\u001b[0m\n",
            "    [INFO] | Limiting to 700 images.\u001b[0m\n",
            "    [INFO] | Download of 700 images in train.\u001b[0m\n",
            "100% 700/700 [07:15<00:00,  1.61it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Human head of train.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPHzyXyvj8wW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "684fe7af-ef98-4b06-be8e-fbdcd0d3c24c"
      },
      "source": [
        "!python3 main.py downloader -y --classes Human_head --type_csv validation --limit 200 --yoloLabelStyle --Dataset /content/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    [INFO] |  saving dataset configurations at /content/config.json\u001b[0m\n",
            "\u001b[92m\n",
            "\t\t   ___   _____  ______            _    _       _    _  \n",
            "\t\t .'   `.|_   _||_   _ `.         | |  | |     | |  | |    \n",
            "\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_    |  | | |   \n",
            "\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _|     | | | \n",
            "\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_       | |\n",
            "\t\t `.___.'|_____||______.'   \\__/     |_____|     |_|\n",
            "\t\u001b[0m\n",
            "\u001b[92m\n",
            "             _____                    _                 _             \n",
            "            (____ \\                  | |               | |            \n",
            "             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n",
            "            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n",
            "            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n",
            "            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n",
            "                                                          \n",
            "        \u001b[0m\n",
            "    [INFO] | Downloading Human head.\u001b[0m\n",
            "\n",
            "\u001b[95mHuman head\u001b[0m\n",
            "    [INFO] | Downloading validation images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 2303 online images for validation.\u001b[0m\n",
            "    [INFO] | Limiting to 200 images.\u001b[0m\n",
            "    [INFO] | Download of 200 images in validation.\u001b[0m\n",
            "100% 200/200 [02:15<00:00,  1.48it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Human head of validation.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pefrsXx_HUR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a501d53-3ee7-420e-c65c-123f64f83fb7"
      },
      "source": [
        "!python3 main.py downloader -y --classes Human_head --type_csv test --limit 100 --yoloLabelStyle --Dataset /content/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    [INFO] |  saving dataset configurations at /content/config.json\u001b[0m\n",
            "\u001b[92m\n",
            "\t\t   ___   _____  ______            _    _       _    _  \n",
            "\t\t .'   `.|_   _||_   _ `.         | |  | |     | |  | |    \n",
            "\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_    |  | | |   \n",
            "\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _|     | | | \n",
            "\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_       | |\n",
            "\t\t `.___.'|_____||______.'   \\__/     |_____|     |_|\n",
            "\t\u001b[0m\n",
            "\u001b[92m\n",
            "             _____                    _                 _             \n",
            "            (____ \\                  | |               | |            \n",
            "             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n",
            "            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n",
            "            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n",
            "            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n",
            "                                                          \n",
            "        \u001b[0m\n",
            "    [INFO] | Downloading Human head.\u001b[0m\n",
            "\u001b[91m   [ERROR] | Missing the test-annotations-bbox.csv file.\u001b[0m\n",
            "\u001b[94m[DOWNLOAD] | Automatic download.\u001b[0m\n",
            "...100%, 49 MB, 27283 KB/s, 1 seconds passed\n",
            "\u001b[94m[DOWNLOAD] | File test-annotations-bbox.csv downloaded into ./OID/csv_folder/test-annotations-bbox.csv.\u001b[0m\n",
            "\n",
            "\u001b[95mHuman head\u001b[0m\n",
            "    [INFO] | Downloading test images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 9945 online images for test.\u001b[0m\n",
            "    [INFO] | Limiting to 100 images.\u001b[0m\n",
            "    [INFO] | Download of 100 images in test.\u001b[0m\n",
            "100% 100/100 [01:15<00:00,  1.33it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Human head of test.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CHAyx-ssrRU"
      },
      "source": [
        "# Train Data using Yolov5 pretrained models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUQ07C7mtrBa"
      },
      "source": [
        "# Data Config File\n",
        "Details for the dataset you want to train your model on are defined by the data config YAML file. The following parameters have to be defined in a data config file:\n",
        "\n",
        "* train, test, and val: Locations of train, test, and validation images.\n",
        "* nc: Number of classes in the dataset.\n",
        "* names: Names of the classes in the dataset. The index of the classes in this * list would be used as an identifier for the class names in the code.\n",
        "* Create a new file called people_det_data.yaml and place it in the yolov5/data folder. Then populate it with the following.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "train: /content/train/Human body/images/ \n",
        "val:  /content/validation/Human body/images/\n",
        "test: /content/test/Human body/images/\n",
        "\n",
        "# number of classes\n",
        "nc: 1\n",
        "\n",
        "# class names\n",
        "names: [\"person\"]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv3CLekNENjz"
      },
      "source": [
        "# Train the model YOLOv5\n",
        "In the downloaded package of YOLOv5, we have 4 versions of the model: YOLOv5s, YOLOv5m, YOLOv5l and, YOLOv5x. I will use the small one and it is YOLOv5s. You guessed it the letters s, m, l, and x is for the model size.\n",
        "In the training command, you give the selected model these arguments:\n",
        "* **img**: input image size\n",
        "* **batch**: batch size\n",
        "* **epochs**: number of training epochs\n",
        "* **data**: our yaml file created before\n",
        "* **cfg**: the chosen model here I used the small one\n",
        "* **weights**: a custom path to weights if empty, it will be saved in yolov5/runs/\n",
        "* **train**/yolov5_results/weights\n",
        "* **name**: result names\n",
        "* **device**: 0 to use GPU\n",
        "* **cache**: cache images for faster training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzsc-cCiD9JI"
      },
      "source": [
        "Train using yolov5s"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRQS1lw1qJKg"
      },
      "source": [
        "%cd /content/yolov5\n",
        "!python train.py --img 640 --cfg yolov5s.yaml --hyp hyp.scratch.yaml --batch 16 --epochs 30 --data people_det_data.yaml --weights yolov5s.pt --workers 24 --name yolo_people_det --device 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwowCzxbEBYh"
      },
      "source": [
        "or train using yolov5s6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "msqUTd52DT_p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a36a546-6e42-45fc-f494-d6c12f4721c2"
      },
      "source": [
        "%cd /content/yolov5\n",
        "!python train.py --img 1280 --cfg yolov5s6.yaml --hyp hyp.scratch.yaml --batch 16 --epochs 100 --data people_det_data.yaml --weights yolov5s6.pt --name yolo_people_det"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s6.pt, cfg=yolov5s6.yaml, data=people_det_data.yaml, hyp=hyp.scratch.yaml, epochs=100, batch_size=16, imgsz=1280, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, name=yolo_people_det, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ðŸš€ v6.0-39-g5d4258f torch 1.9.0+cu111 CUDA:0 (Tesla K80, 11441.1875MB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mWeights & Biases: \u001b[0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5s6.pt to yolov5s6.pt...\n",
            "100% 24.5M/24.5M [00:01<00:00, 22.6MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1    885504  models.common.Conv                      [256, 384, 3, 2]              \n",
            "  8                -1  1    665856  models.common.C3                        [384, 384, 1]                 \n",
            "  9                -1  1   1770496  models.common.Conv                      [384, 512, 3, 2]              \n",
            " 10                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            " 11                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 12                -1  1    197376  models.common.Conv                      [512, 384, 1, 1]              \n",
            " 13                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 14           [-1, 8]  1         0  models.common.Concat                    [1]                           \n",
            " 15                -1  1    813312  models.common.C3                        [768, 384, 1, False]          \n",
            " 16                -1  1     98816  models.common.Conv                      [384, 256, 1, 1]              \n",
            " 17                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 18           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 19                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 20                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 21                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 22           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 24                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 25          [-1, 20]  1         0  models.common.Concat                    [1]                           \n",
            " 26                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 27                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 28          [-1, 16]  1         0  models.common.Concat                    [1]                           \n",
            " 29                -1  1    715008  models.common.C3                        [512, 384, 1, False]          \n",
            " 30                -1  1   1327872  models.common.Conv                      [384, 384, 3, 2]              \n",
            " 31          [-1, 12]  1         0  models.common.Concat                    [1]                           \n",
            " 32                -1  1   1313792  models.common.C3                        [768, 512, 1, False]          \n",
            " 33  [23, 26, 29, 32]  1     23112  models.yolo.Detect                      [1, [[19, 27, 44, 40, 38, 94], [96, 68, 86, 152, 180, 137], [140, 301, 303, 264, 238, 542], [436, 615, 739, 380, 925, 792]], [128, 256, 384, 512]]\n",
            "Model Summary: 355 layers, 12322312 parameters, 12322312 gradients, 16.2 GFLOPs\n",
            "\n",
            "Transferred 450/459 items from yolov5s6.pt\n",
            "Scaled weight_decay = 0.0005\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD with parameter groups 75 weight, 79 weight (no decay), 79 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mversion 1.0.3 required by YOLOv5, but version 0.1.12 is currently installed\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning '/content/train/Human head/labels' images and labels...700 found, 0 missing, 0 empty, 0 corrupted: 100% 700/700 [00:00<00:00, 1786.71it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/train/Human head/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/validation/Human head/labels' images and labels...200 found, 0 missing, 0 empty, 0 corrupted: 100% 200/200 [00:00<00:00, 698.32it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/validation/Human head/labels.cache\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
            "Plotting labels... \n",
            "\n",
            "\u001b[34m\u001b[1mautoanchor: \u001b[0mAnalyzing anchors... anchors/target = 6.15, Best Possible Recall (BPR) = 0.9990\n",
            "Image sizes 1280 train, 1280 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/yolo_people_det\u001b[0m\n",
            "Starting training for 100 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      0/99     11.3G    0.1018   0.06899         0        92      1280: 100% 44/44 [03:20<00:00,  4.55s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:19<00:00,  2.82s/it]\n",
            "                 all        200        516     0.0161     0.0194    0.00294   0.000606\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      1/99     11.3G   0.07709     0.063         0       117      1280: 100% 44/44 [03:14<00:00,  4.43s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:15<00:00,  2.18s/it]\n",
            "                 all        200        516      0.195      0.163     0.0785     0.0239\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      2/99     11.3G   0.05909   0.05733         0        69      1280: 100% 44/44 [03:15<00:00,  4.43s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:13<00:00,  1.93s/it]\n",
            "                 all        200        516      0.621      0.366      0.412      0.145\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      3/99     11.3G   0.05541   0.04501         0       114      1280: 100% 44/44 [03:14<00:00,  4.41s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:12<00:00,  1.84s/it]\n",
            "                 all        200        516      0.386       0.51      0.355     0.0964\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      4/99     11.3G   0.05588   0.04271         0       100      1280: 100% 44/44 [03:13<00:00,  4.39s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:12<00:00,  1.81s/it]\n",
            "                 all        200        516      0.634      0.506      0.536      0.211\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      5/99     11.3G   0.05148   0.03895         0        59      1280: 100% 44/44 [03:13<00:00,  4.41s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:12<00:00,  1.78s/it]\n",
            "                 all        200        516      0.401      0.663      0.394     0.0953\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      6/99     11.3G   0.04907   0.03813         0        94      1280: 100% 44/44 [03:14<00:00,  4.42s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:12<00:00,  1.77s/it]\n",
            "                 all        200        516      0.494      0.657      0.538      0.198\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      7/99     11.3G   0.04592   0.03601         0        88      1280: 100% 44/44 [03:14<00:00,  4.43s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:12<00:00,  1.77s/it]\n",
            "                 all        200        516      0.601      0.702      0.596       0.22\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      8/99     11.3G   0.04418   0.03661         0       129      1280: 100% 44/44 [03:15<00:00,  4.45s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:12<00:00,  1.75s/it]\n",
            "                 all        200        516      0.643       0.68      0.667      0.331\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "      9/99     11.3G   0.04371   0.03726         0        85      1280: 100% 44/44 [03:14<00:00,  4.41s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:12<00:00,  1.76s/it]\n",
            "                 all        200        516      0.667      0.661      0.651      0.254\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     10/99     11.3G   0.04134   0.03459         0        93      1280: 100% 44/44 [03:15<00:00,  4.45s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:12<00:00,  1.74s/it]\n",
            "                 all        200        516      0.746      0.672      0.722      0.333\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     11/99     11.3G   0.04339   0.03484         0        69      1280: 100% 44/44 [03:14<00:00,  4.42s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:12<00:00,  1.74s/it]\n",
            "                 all        200        516      0.662      0.672      0.662      0.266\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     12/99     11.3G   0.04344   0.03284         0        52      1280: 100% 44/44 [03:14<00:00,  4.42s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:12<00:00,  1.75s/it]\n",
            "                 all        200        516      0.614      0.702      0.638      0.292\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     13/99     11.3G   0.04084    0.0333         0        68      1280: 100% 44/44 [03:14<00:00,  4.42s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:12<00:00,  1.74s/it]\n",
            "                 all        200        516      0.749      0.725      0.731      0.344\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     14/99     11.3G   0.04024   0.03376         0       126      1280: 100% 44/44 [03:16<00:00,  4.46s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:12<00:00,  1.75s/it]\n",
            "                 all        200        516      0.712      0.722      0.715      0.376\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     15/99     11.3G   0.03811   0.03245         0        53      1280: 100% 44/44 [03:16<00:00,  4.46s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:12<00:00,  1.77s/it]\n",
            "                 all        200        516      0.712      0.734      0.709      0.369\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     16/99     11.3G   0.03723   0.03358         0       199      1280: 100% 44/44 [03:16<00:00,  4.47s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:12<00:00,  1.78s/it]\n",
            "                 all        200        516      0.674      0.754      0.704      0.339\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     17/99     11.3G   0.03565   0.03383         0       144      1280: 100% 44/44 [03:17<00:00,  4.48s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:12<00:00,  1.77s/it]\n",
            "                 all        200        516      0.704      0.722       0.66      0.322\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     18/99     11.3G   0.03584   0.03081         0       169      1280: 100% 44/44 [03:16<00:00,  4.46s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:12<00:00,  1.75s/it]\n",
            "                 all        200        516      0.764      0.723      0.681      0.313\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     19/99     11.3G   0.03779   0.03272         0       116      1280: 100% 44/44 [03:16<00:00,  4.46s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:12<00:00,  1.76s/it]\n",
            "                 all        200        516      0.746      0.729      0.714      0.305\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     20/99     11.3G   0.03671    0.0323         0        62      1280: 100% 44/44 [03:15<00:00,  4.45s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:12<00:00,  1.76s/it]\n",
            "                 all        200        516      0.707      0.692      0.684      0.352\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     21/99     11.3G   0.03547   0.03138         0       152      1280: 100% 44/44 [03:15<00:00,  4.45s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:12<00:00,  1.76s/it]\n",
            "                 all        200        516      0.753      0.694      0.692      0.342\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     22/99     11.3G   0.03461    0.0322         0        80      1280: 100% 44/44 [03:16<00:00,  4.46s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:12<00:00,  1.77s/it]\n",
            "                 all        200        516      0.783      0.699      0.699      0.366\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     23/99     11.3G   0.03296   0.03183         0       131      1280: 100% 44/44 [03:16<00:00,  4.47s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:12<00:00,  1.76s/it]\n",
            "                 all        200        516      0.798      0.651      0.695      0.373\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     24/99     11.3G   0.03296   0.03179         0       115      1280: 100% 44/44 [03:16<00:00,  4.46s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:12<00:00,  1.76s/it]\n",
            "                 all        200        516      0.773      0.698      0.682      0.344\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     25/99     11.3G   0.03237   0.03288         0        88      1280: 100% 44/44 [03:16<00:00,  4.47s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:12<00:00,  1.75s/it]\n",
            "                 all        200        516      0.771      0.667      0.693      0.351\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     26/99     11.3G   0.03184   0.03165         0        45      1280: 100% 44/44 [03:16<00:00,  4.47s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:12<00:00,  1.75s/it]\n",
            "                 all        200        516      0.778      0.686       0.68      0.376\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     27/99     11.3G   0.02969   0.02949         0        81      1280: 100% 44/44 [03:16<00:00,  4.46s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:12<00:00,  1.76s/it]\n",
            "                 all        200        516       0.78      0.752      0.751      0.411\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     28/99     11.3G   0.03093   0.03065         0       117      1280: 100% 44/44 [03:16<00:00,  4.47s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:12<00:00,  1.76s/it]\n",
            "                 all        200        516      0.746      0.705      0.693      0.398\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     29/99     11.3G   0.02852   0.02985         0        74      1280: 100% 44/44 [03:16<00:00,  4.46s/it]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 7/7 [00:12<00:00,  1.76s/it]\n",
            "                 all        200        516      0.775      0.672       0.69      0.385\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls    labels  img_size\n",
            "     30/99     11.3G   0.02811   0.02856         0       104      1280:  52% 23/44 [01:42<01:34,  4.48s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpgKjmDfSIOJ"
      },
      "source": [
        "Save the trained model and weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sep9TtB2v2TE"
      },
      "source": [
        "!zip -r /content/yolov5/runs/train/yolo_people_det.zip /content/yolov5/runs/train/yolo_people_det"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcxWzeQE7jaN"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('/content/yolov5/runs/train/yolo_people_det.zip')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omgf0RdhSsJP"
      },
      "source": [
        "# Inference\n",
        "There are many ways to run inference using the detect.py file.\n",
        "\n",
        "The source flag defines the source of our detector, which can be:\n",
        "* A single image\n",
        "* A folder of images\n",
        "* Video\n",
        "* Webcam \\\n",
        "...and various other formats. We want to run it over our test images so we set the source flag to /content/test/Human.\n",
        "\n",
        "* The weights flag defines the path of the model which we want to run our detector with.\n",
        "* conf flag is the thresholding objectness confidence.\n",
        "* name flag defines where the detections are stored. We set this flag to yolo_road_det; therefore, the detections would be stored in runs/detect/yolo_road_det/.\n",
        "With all options decided, let us run inference over our test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_vH1wLvSWMx"
      },
      "source": [
        "%cd /content/yolov5\n",
        "!python detect.py --source /content/yolov5/data/videos/people_walking.mp4 --weights runs/train/yolo_people_det/weights/best.pt --conf 0.25 --name yolo_people_det"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4G0dPvpTevj"
      },
      "source": [
        "%rm -rf /content/validation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SW33xzcz9a1x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}